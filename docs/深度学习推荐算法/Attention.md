# 注意力机制的应用(AFM、DIN)



## AFM

AFM可以看做是NFM的延续，在NFM模型中，不同特征域的Embedding向量经过特征交叉池化层的交叉，进行了加和操作，加和池化操作**平等地对待了所有交叉特征**，没有考虑到不同特征对结果的影响，事实上消解了大量有价值的信息。



AFM模型引入注意力机制是通过在特征交叉层和最终的输出层之间添加注意力网络实现的，注意力网络为每一个交叉特征添加了一个权重。网络结构如下：

![img](https://blog-1252832257.cos.ap-shanghai.myqcloud.com/25334281-3243ae2ad9a399e6.png)

AFM的特征交叉过程和NFM相同，也是利用了元素积的操作得到两两特征之间的交叉结果。

注意力得分的计算, 用来一个全连接层和softmax：
$$
a_{ij}^{'} = h^\top ReLU(W(v_i\cdot v_j)x_ix_j+b)\\
a_{ij} = softmax(a_{ij}^{'})
$$
最终的结果即为：
$$
y_{AFM}(x) = w_0 + \sum_{i=1}^n w_ix_i + P^\top\sum_{i=1}^n\sum_{j=i+1}^na_{ij}(v_i\cdot v_j)x_ix_j
$$
AFM在FM模型的基础上，引入了attention机制，使模型能够有效学习二阶特征项的权重。不过该网络最后实际上是对各交叉特征进行加权求和，然后通过一个全连接层P，并没有发挥DNN的优势。

## DIN

> Deep Interest Network(DIIN)是2018年阿里巴巴提出来的模型， 该模型基于业务的观察，从实际应用的角度进行改进，相比于之前很多“学术风”的深度模型， 该模型更加具有业务气息

DIN核心思想可以归纳为：
1、 基于物品的推荐，也就是判断购物购买过的物品，进而判断是否和本广告物品相关
2、 用户购买过的物品，权重不一样。比如，推荐物品为奶粉，用户购买过笔记本电脑，购买过尿不湿，显然，尿不湿的奶粉的相关性高。因此需要提高尿不湿的权重。

**Base model**



![image-20220729152140399](https://blog-1252832257.cos.ap-shanghai.myqcloud.com/image-20220729152140399.png)

Base Model 将用户历史购买记录使用加和池化得到一个向量，用来表示用户的兴趣方向。这种方式认为所有的历史标的物的重要性对候选标的物都是同等重要的，显然这是不对的。用户的历史行为特征和当前的候选广告特征在全都拼起来给神经网络之前，是一点交互的过程都没有， 而拼起来之后给神经网络，虽然是有了交互了，但是原来的一些信息，比如，每个历史商品的信息会丢失了一部分，因为这个与当前候选广告商品交互的是池化后的历史特征embedding， 这个embedding是综合了所有的历史商品信息。

对此，DIN当前候选广告和用户的历史行为之间引入了注意力机制。



![img](https://blog-1252832257.cos.ap-shanghai.myqcloud.com/20210118220015871.png)

相比Base Model，DIN增加了Activation Unit用来计算历史商品与候选商品的相关性，作为权重与原来的商品embedding相乘，在做求和。
$$
v_U(A) = f(v_A,e_1,e_2,...,e_H) = \sum_{j=1}^Ha(e_j,v_A)e_j = \sum_{j=1}^Hw_je_j
$$
其中activation unit的输入包括两个部分，一个是原始的用户行为embedding向量、广告embedding向量；另外一个是两者Embedding向量经过外积计算后得到的向量，文章指出这种方式有利于relevance modeling。

此外，这里的权重和不是1，没有经过softmax