# FM 与深度学习模型的融合（FNN、DeepFM、NFM）

>本节介绍基本的FM与深度学习融合的模型，FNN、DeepFM、NFM

## FNN

在神经网络的参数初始化过程中,往往采用不带有先验信息地随机初始化,但由于Embedding层的输入极端稀疏化,在随机梯度下降的过程中,只有与非零特征相连的Embedding层的权重会被更新**,导致Embedding层的收敛速度很慢**,且Embedding层的参数数量往往占整个神经网络参数数量的大半以上,模型的收敛速度往往受限于Embedding层。

针对这个难题,FNN使用FM模型训练好的各特征隐向量初始化Embedding层的参数,相当于在初始化神经网络参数时**引入了先验信息**,这样一来神经网络训练的起点更接近于目标的最优点,加速了神经网络的收敛。



<img src="https://blog-1252832257.cos.ap-shanghai.myqcloud.com/c5db7edbf6184825aa809ca77d7d06f3.png" alt="img" style="zoom:67%;" />

FNN的训练方式带有传统机器学习浓厚的烙印，并不想深度学习模型那样是end-to-end的，而是两阶段训练方式。
阶段一：使用FM模型训练得到每个field的embedding向量。
阶段二：基于阶段一的embedding向量初始化MLP里的embedding向量，也就是上图中的Dense Real Layer。然后训练MLP网络得到最终的模型。

**优点：**

引入DNN对特征进行更高阶组合，减少特征工程，能在一定程度上增强FM的学习能力，这种尝试为后续深度推荐模型的发展提供了新的思路。

**缺点：**

- 两阶段训练模式，在应用过程中不方便，且模型能力受限于FM表征能力的上限。
- FNN专注于高阶组合特征，但是却没有对低阶特征进行建模。

## DeepFM

> DeepFM 是 Deep 与 FM 结合的产物，也是 Wide&Deep 的改进版，只是将其中的 LR 替换成了 FM

FNN和PNN模型仍然有一个比较明显的尚未解决的缺点：对于低阶组合特征学习到的比较少，这一点主要是由于FM和DNN的串行方式导致的，也就是虽然FM学到了低阶特征组合，但是DNN的全连接结构导致低阶特征并不能在DNN的输出端较好的表现。因此Wide&Deep模型将低阶特征组合和DNN改为并行的模式，但在Wide端需要精巧的特征工程设计。

![image-20210225180556628](http://ryluo.oss-cn-chengdu.aliyuncs.com/%E5%9B%BE%E7%89%87image-20210225180556628.png)



DeepFM的改进主要是针对Wide&Deep模型的Wide部分不具备自动特征组合的能力的缺陷的，改动动机和Deep&Cross模型一直，DCN是利用多层Cross网络进行特征组合。



## NFM

FM模型是一个二阶特征交叉模型，受到组合爆炸问题的困扰，几乎不可能扩展到三阶之上。

2017年，新加坡国立大学的研究人员利用深度神经网络改进FM模型，提出NFM。
$$
y(x)=w_0+\sum_{i=1}^Nw_ix_i+f(x)
$$
NFM模型的主要思路是用一个表达能力更强的函数代替原FM中二阶隐向量内积的部分。

DNN部分的网络结构

![image-20220728225318307](https://blog-1252832257.cos.ap-shanghai.myqcloud.com/image-20220728225318307.png)

Bi-Interaction Pooling layer

![image-20220728223523295](https://blog-1252832257.cos.ap-shanghai.myqcloud.com/image-20220728223523295.png)

每一个特征的embedding向量做元素积，得到一个k维向量。这部分不需要额外的参数进行学习，并且可以在线性的时间内完成。

其余部分都比较常规，不再介绍。

另外，NFM的一阶部分为一个线性模型，NFM也可以看做事Wide&Deep模型的延伸。

NFM相比较于其他模型的核心创新点是特征交叉池化层，基于它，实现了FM和DNN的无缝连接，使得DNN可以在底层就学习到包含更多信息的组合特征



## 模型的优点和局限性

在经典多层神经网络上加入特征交互的操作，让模型具备更强的非线性表达能力。

但特征工程的思路走到这里已经是几乎穷尽了可能的尝试，模型进一步提升的空间非常小，这也是这类模型的局限所在。

在这之后，深度学习模型开始探索结构上的尝试，诸如注意力，序列模型，强化学习等。
